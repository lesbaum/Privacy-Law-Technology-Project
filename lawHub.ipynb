{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import bert.tokenization as tokenization\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=False)\n",
    "train=pd.read_csv(r\"C:\\Users\\peter\\Documents\\GitHub\\Privacy-Law-Technology-Project\\train.csv\")\n",
    "test=pd.read_csv(r\"C:\\Users\\peter\\Documents\\GitHub\\Privacy-Law-Technology-Project\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
    "\n",
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    net = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    out = tf.keras.layers.Dense(2, activation='softmax')(net)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_len = 150\n",
    "train_input = bert_encode(train.text.values, tokenizer, max_len=max_len)\n",
    "test_input = bert_encode(test.text.values, tokenizer, max_len=max_len)\n",
    "train_labels =tf.keras.utils.to_categorical(train.label.astype('int32'), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 150)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 150)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 150)]        0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     [(None, 1024),       335141889   ['input_word_ids[0][0]',         \n",
      "                                 (None, 150, 1024)]               'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 1024)        0           ['keras_layer_1[0][1]']          \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           65600       ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 32)           2080        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 32)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 2)            66          ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 335,209,635\n",
      "Trainable params: 67,746\n",
      "Non-trainable params: 335,141,889\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/7\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8029 - accuracy: 0.5683 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.51429, saving model to model.h5\n",
      "3/3 [==============================] - 82s 22s/step - loss: 0.8029 - accuracy: 0.5683 - val_loss: 0.6841 - val_accuracy: 0.5143\n",
      "Epoch 2/7\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.5971 \n",
      "Epoch 2: val_accuracy improved from 0.51429 to 0.62857, saving model to model.h5\n",
      "3/3 [==============================] - 67s 22s/step - loss: 0.6763 - accuracy: 0.5971 - val_loss: 0.6423 - val_accuracy: 0.6286\n",
      "Epoch 3/7\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6435 - accuracy: 0.6187 \n",
      "Epoch 3: val_accuracy improved from 0.62857 to 0.74286, saving model to model.h5\n",
      "3/3 [==============================] - 65s 21s/step - loss: 0.6435 - accuracy: 0.6187 - val_loss: 0.6035 - val_accuracy: 0.7429\n",
      "Epoch 4/7\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.7266 \n",
      "Epoch 4: val_accuracy did not improve from 0.74286\n",
      "3/3 [==============================] - 63s 20s/step - loss: 0.5782 - accuracy: 0.7266 - val_loss: 0.5681 - val_accuracy: 0.7429\n",
      "Epoch 5/7\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.6906 \n",
      "Epoch 5: val_accuracy improved from 0.74286 to 0.82857, saving model to model.h5\n",
      "3/3 [==============================] - 65s 21s/step - loss: 0.5802 - accuracy: 0.6906 - val_loss: 0.4863 - val_accuracy: 0.8286\n",
      "Epoch 6/7\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.7338 \n",
      "Epoch 6: val_accuracy improved from 0.82857 to 0.88571, saving model to model.h5\n",
      "3/3 [==============================] - 65s 21s/step - loss: 0.5177 - accuracy: 0.7338 - val_loss: 0.4272 - val_accuracy: 0.8857\n",
      "Epoch 7/7\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5083 - accuracy: 0.7482 \n",
      "Epoch 7: val_accuracy did not improve from 0.88571\n",
      "3/3 [==============================] - 63s 20s/step - loss: 0.5083 - accuracy: 0.7482 - val_loss: 0.3851 - val_accuracy: 0.8286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(bert_layer, max_len=max_len)\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers[-5:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
    "\n",
    "train_history = model.fit(\n",
    "    train_input, train_labels, \n",
    "    validation_split=0.2,\n",
    "    epochs=7,\n",
    "    callbacks=[checkpoint, earlystopping],\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_weights('model.h5')\n",
    "test_pred = model.predict(test_input)\n",
    "test['predicted_values'] = test_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            company_name                                               text   \n",
      "0   Montessori Preschool  EDOKI ACADEMY only collects the data necessary...  \\\n",
      "1   Montessori Preschool  To request the deletion of your Personal Data ...   \n",
      "2   Montessori Preschool  A cookie is a string of text information trans...   \n",
      "3                   LEGO  Request erasure You have the right to request ...   \n",
      "4                   LEGO  Personal data is any information about a perso...   \n",
      "5                   LEGO  If we change the way we handle your personal d...   \n",
      "6            Fox & Sheep  Fox & Sheep is a “data controller” as defined ...   \n",
      "7            Fox & Sheep  Insofar as your personal data is processed bas...   \n",
      "8            Fox & Sheep  We do not knowingly collect personal informati...   \n",
      "9      The Fennec Studio  We will collect and use of personal informatio...   \n",
      "10     The Fennec Studio  his Privacy Policy governs the manner in which...   \n",
      "11     The Fennec Studio  We are committed to conducting our business in...   \n",
      "12              PlayKids  PlayKids undertakes to collect and process the...   \n",
      "13              PlayKids  PlayKids uses its best efforts and acts in goo...   \n",
      "14              PlayKids   The user has the right not to supply or revok...   \n",
      "15           Mobinautica  Mobinautica does not knowingly collect any per...   \n",
      "16           Mobinautica  Under the GDPR you have a right to have Mobina...   \n",
      "17           Mobinautica  When necessary, we may also disclose personal ...   \n",
      "18                Nestle  We collect various types of information from y...   \n",
      "19                Nestle   Any information about the computer system or ...   \n",
      "20                Nestle  here provided by law, you can (i) request dele...   \n",
      "\n",
      "    label                           predicted_values  \n",
      "0       0   [0.7285614013671875, 0.2714385986328125]  \n",
      "1       1  [0.28413188457489014, 0.7158680558204651]  \n",
      "2       2  [0.6530939936637878, 0.34690597653388977]  \n",
      "3       1  [0.30980485677719116, 0.6901952028274536]  \n",
      "4       0  [0.5787543654441833, 0.42124566435813904]  \n",
      "5       2   [0.4341321289539337, 0.5658678412437439]  \n",
      "6       2   [0.5228089690208435, 0.4771910011768341]  \n",
      "7       1  [0.45841020345687866, 0.5415897965431213]  \n",
      "8       0  [0.6249902248382568, 0.37500980496406555]  \n",
      "9       0   [0.581653356552124, 0.41834670305252075]  \n",
      "10      2   [0.6191645860671997, 0.3808353841304779]  \n",
      "11      2   [0.6751754283905029, 0.3248245120048523]  \n",
      "12      0  [0.49860766530036926, 0.5013923048973083]  \n",
      "13      2    [0.538701057434082, 0.4612988829612732]  \n",
      "14      1  [0.5774580240249634, 0.42254194617271423]  \n",
      "15      0   [0.6350246071815491, 0.3649754524230957]  \n",
      "16      1  [0.18528418242931366, 0.8147158026695251]  \n",
      "17      2     [0.493663489818573, 0.506336510181427]  \n",
      "18      0  [0.6159723401069641, 0.38402771949768066]  \n",
      "19      2  [0.48186901211738586, 0.5181309580802917]  \n",
      "20      1     [0.4812515676021576, 0.51874840259552]  \n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k in test.predicted_values:\n",
    "    if(abs(k[0] - k[1]) > .25):\n",
    "        if(k[0] > k[1]):\n",
    "            \n",
    "            test.at[count,\"final_prediction\"] = 0\n",
    "        else:\n",
    "            test.at[count,\"final_prediction\"] = 1\n",
    "    else:\n",
    "        test.at[count,\"final_prediction\"] = 2\n",
    "    count = count + 1\n",
    "\n",
    "numRight = 0\n",
    "numTotal = len(test)\n",
    "for i in range(len(test)):\n",
    "    if(test.iloc[i][\"label\"] == test.iloc[i][\"final_prediction\"]):\n",
    "        numRight = numRight + 1\n",
    "    elif(test.iloc[i][\"label\"] != 2 and test.iloc[i][\"final_prediction\"] ==2):\n",
    "        numRight = numRight + 1\n",
    "\n",
    "print(numRight/numTotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            company_name                                               text   \n",
      "2   Montessori Preschool  A cookie is a string of text information trans...  \\\n",
      "11     The Fennec Studio  We are committed to conducting our business in...   \n",
      "\n",
      "    label                           predicted_values  final_prediction  \n",
      "2       2  [0.6530939936637878, 0.34690597653388977]               0.0  \n",
      "11      2   [0.6751754283905029, 0.3248245120048523]               0.0  \n"
     ]
    }
   ],
   "source": [
    "print(test[(test.label == 2) & (test.final_prediction != 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     1\n",
      "2     2\n",
      "3     1\n",
      "4     0\n",
      "5     2\n",
      "6     2\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    2\n",
      "11    2\n",
      "12    0\n",
      "13    2\n",
      "14    1\n",
      "15    0\n",
      "16    1\n",
      "17    2\n",
      "18    0\n",
      "19    2\n",
      "20    1\n",
      "Name: label, dtype: int64\n",
      "0     0.0\n",
      "1     1.0\n",
      "2     0.0\n",
      "3     1.0\n",
      "4     2.0\n",
      "5     2.0\n",
      "6     2.0\n",
      "7     2.0\n",
      "8     2.0\n",
      "9     2.0\n",
      "10    2.0\n",
      "11    0.0\n",
      "12    2.0\n",
      "13    2.0\n",
      "14    2.0\n",
      "15    0.0\n",
      "16    1.0\n",
      "17    2.0\n",
      "18    2.0\n",
      "19    2.0\n",
      "20    2.0\n",
      "Name: final_prediction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(test[\"label\"])\n",
    "print(test[\"final_prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sarah Jessica Sebastian', 'Sebastian Rivera', 'Ben Lepsch']\n",
      "['+1 (630)-200-9399']\n",
      "['privacy@petermertka.com']\n",
      "['18 rue', '92120 Montrouge']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "string = \"A cookie is a Sarah Jessica Sebastian Parker string of text information Sebastian Rivera transferred from a website to your computer's hard drive so that Ben Lepsch the website can remember you. Cookies can help a website adapt content more quickly to your interests. Most importantly websites use cookies. In general, a cookie contains the name of the domain of origin of the cookie; the of the cookie and a value, namely a unique number created randomly.\"\n",
    "regex = re.compile(r\"[A-Z][a-z]+,?\\s+(?:[A-Z][a-z]*\\.?\\s*)?[A-Z][a-z]+\")\n",
    "print(regex.findall(string))\n",
    "\n",
    "phoneNumberRegex = re.compile(r'\\+?\\d{1,4}?[-.\\s]?\\(?\\d{1,3}?\\)?[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,9}')\n",
    "string2 = \"call me at Telephone +1 (630)-200-9399\"\n",
    "print(phoneNumberRegex.findall(string2))\n",
    "\n",
    "emailRegex = re.compile(r'\\S+@\\S+')\n",
    "string3 = \"please email me at privacy@petermertka.com\"\n",
    "print(emailRegex.findall(string3))\n",
    "\n",
    "addressRegex = re.compile(r'\\b\\d{1,5} [a-zA-Z0-9 \\-.,#&]*[a-zA-Z0-9]\\b')\n",
    "string4 = \"my address is 18 rue Barbès 92120 Montrouge (France) \"\n",
    "print(addressRegex.findall(string4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
