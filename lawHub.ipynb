{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import bert.tokenization as tokenization\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=False)\n",
    "train=pd.read_csv(r\"C:\\Users\\peter\\Documents\\GitHub\\Privacy-Law-Technology-Project\\train.csv\")\n",
    "test=pd.read_csv(r\"C:\\Users\\peter\\Documents\\GitHub\\Privacy-Law-Technology-Project\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
    "\n",
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    net = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    out = tf.keras.layers.Dense(2, activation='softmax')(net)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_len = 150\n",
    "train_input = bert_encode(train.text.values, tokenizer, max_len=max_len)\n",
    "test_input = bert_encode(test.text.values, tokenizer, max_len=max_len)\n",
    "train_labels =tf.keras.utils.to_categorical(train.label.astype('int32'), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 150)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 150)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 150)]        0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       [(None, 1024),       335141889   ['input_word_ids[0][0]',         \n",
      "                                 (None, 150, 1024)]               'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 1024)        0           ['keras_layer[1][1]']            \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           65600       ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           2080        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            66          ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 335,209,635\n",
      "Trainable params: 67,746\n",
      "Non-trainable params: 335,141,889\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/7\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.8642 - accuracy: 0.4892 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.57143, saving model to model.h5\n",
      "5/5 [==============================] - 72s 14s/step - loss: 0.8642 - accuracy: 0.4892 - val_loss: 0.6653 - val_accuracy: 0.5714\n",
      "Epoch 2/7\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6735 - accuracy: 0.6043 \n",
      "Epoch 2: val_accuracy improved from 0.57143 to 0.80000, saving model to model.h5\n",
      "5/5 [==============================] - 64s 13s/step - loss: 0.6735 - accuracy: 0.6043 - val_loss: 0.5367 - val_accuracy: 0.8000\n",
      "Epoch 3/7\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.6034 - accuracy: 0.7050 \n",
      "Epoch 3: val_accuracy did not improve from 0.80000\n",
      "5/5 [==============================] - 63s 13s/step - loss: 0.6034 - accuracy: 0.7050 - val_loss: 0.5038 - val_accuracy: 0.7714\n",
      "Epoch 4/7\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.7986 \n",
      "Epoch 4: val_accuracy improved from 0.80000 to 0.88571, saving model to model.h5\n",
      "5/5 [==============================] - 64s 13s/step - loss: 0.5061 - accuracy: 0.7986 - val_loss: 0.4112 - val_accuracy: 0.8857\n",
      "Epoch 5/7\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.7554 \n",
      "Epoch 5: val_accuracy did not improve from 0.88571\n",
      "5/5 [==============================] - 63s 13s/step - loss: 0.4804 - accuracy: 0.7554 - val_loss: 0.3756 - val_accuracy: 0.8571\n",
      "Epoch 6/7\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7698 \n",
      "Epoch 6: val_accuracy did not improve from 0.88571\n",
      "5/5 [==============================] - 62s 13s/step - loss: 0.4399 - accuracy: 0.7698 - val_loss: 0.3590 - val_accuracy: 0.8571\n",
      "Epoch 7/7\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.3680 - accuracy: 0.8273 \n",
      "Epoch 7: val_accuracy did not improve from 0.88571\n",
      "5/5 [==============================] - 62s 13s/step - loss: 0.3680 - accuracy: 0.8273 - val_loss: 0.3415 - val_accuracy: 0.8286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(bert_layer, max_len=max_len)\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers[-5:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
    "\n",
    "train_history = model.fit(\n",
    "    train_input, train_labels, \n",
    "    validation_split=0.2,\n",
    "    epochs=7,\n",
    "    callbacks=[checkpoint, earlystopping],\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_weights('model.h5')\n",
    "test_pred = model.predict(test_input)\n",
    "\n",
    "test['predicted_values'] = test_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            company_name                                               text   \n",
      "0   Montessori Preschool  EDOKI ACADEMY only collects the data necessary...  \\\n",
      "1   Montessori Preschool  To request the deletion of your Personal Data ...   \n",
      "2   Montessori Preschool  A cookie is a string of text information trans...   \n",
      "3                   LEGO  Request erasure You have the right to request ...   \n",
      "4                   LEGO  Personal data is any information about a perso...   \n",
      "5                   LEGO  If we change the way we handle your personal d...   \n",
      "6            Fox & Sheep  Fox & Sheep is a “data controller” as defined ...   \n",
      "7            Fox & Sheep  Insofar as your personal data is processed bas...   \n",
      "8            Fox & Sheep  We do not knowingly collect personal informati...   \n",
      "9      The Fennec Studio  We will collect and use of personal informatio...   \n",
      "10     The Fennec Studio  his Privacy Policy governs the manner in which...   \n",
      "11     The Fennec Studio  We are committed to conducting our business in...   \n",
      "12              PlayKids  PlayKids undertakes to collect and process the...   \n",
      "13              PlayKids  PlayKids uses its best efforts and acts in goo...   \n",
      "14              PlayKids   The user has the right not to supply or revok...   \n",
      "15           Mobinautica  Mobinautica does not knowingly collect any per...   \n",
      "16           Mobinautica  Under the GDPR you have a right to have Mobina...   \n",
      "17           Mobinautica  When necessary, we may also disclose personal ...   \n",
      "18                Nestle  We collect various types of information from y...   \n",
      "19                Nestle   Any information about the computer system or ...   \n",
      "20                Nestle  here provided by law, you can (i) request dele...   \n",
      "\n",
      "    label                           predicted_values  \n",
      "0     0.0   [0.776197075843811, 0.22380292415618896]  \n",
      "1     1.0  [0.24345816671848297, 0.7565418481826782]  \n",
      "2     NaN   [0.5357916355133057, 0.4642083942890167]  \n",
      "3     1.0  [0.32909512519836426, 0.6709048748016357]  \n",
      "4     0.0   [0.4982934296131134, 0.5017065405845642]  \n",
      "5     NaN   [0.3626219928264618, 0.6373779773712158]  \n",
      "6     NaN   [0.6979236602783203, 0.3020763397216797]  \n",
      "7     1.0  [0.34753715991973877, 0.6524627804756165]  \n",
      "8     0.0  [0.49280765652656555, 0.5071923136711121]  \n",
      "9     0.0    [0.59883713722229, 0.40116289258003235]  \n",
      "10    NaN  [0.5714770555496216, 0.42852291464805603]  \n",
      "11    NaN  [0.6612845659255981, 0.33871543407440186]  \n",
      "12    0.0  [0.7569601535797119, 0.24303992092609406]  \n",
      "13    NaN  [0.5610461831092834, 0.43895378708839417]  \n",
      "14    1.0   [0.6638815402984619, 0.3361184298992157]  \n",
      "15    0.0   [0.6840397119522095, 0.3159603178501129]  \n",
      "16    1.0  [0.15889787673950195, 0.8411020636558533]  \n",
      "17    NaN   [0.4661217927932739, 0.5338782668113708]  \n",
      "18    0.0  [0.6936220526695251, 0.30637797713279724]  \n",
      "19    NaN    [0.458966463804245, 0.5410336256027222]  \n",
      "20    1.0   [0.3582397401332855, 0.6417601704597473]  \n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k in test.predicted_values:\n",
    "    if(abs(k[0] - k[1]) > .25):\n",
    "        if(k[0] > k[1]):\n",
    "            \n",
    "            test.at[count,\"final_prediction\"] = 0\n",
    "        else:\n",
    "            test.at[count,\"final_prediction\"] = 1\n",
    "    else:\n",
    "        test.at[count,\"final_prediction\"] = 2\n",
    "    count = count + 1\n",
    "\n",
    "numRight = 0\n",
    "numTotal = len(test)\n",
    "for i in range(len(test)):\n",
    "    if(test.iloc[i][\"label\"] == test.iloc[i][\"final_prediction\"]):\n",
    "        numRight = numRight + 1\n",
    "\n",
    "print(numRight/numTotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.0\n",
      "1     1.0\n",
      "2     NaN\n",
      "3     1.0\n",
      "4     0.0\n",
      "5     NaN\n",
      "6     NaN\n",
      "7     1.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    NaN\n",
      "11    NaN\n",
      "12    0.0\n",
      "13    NaN\n",
      "14    1.0\n",
      "15    0.0\n",
      "16    1.0\n",
      "17    NaN\n",
      "18    0.0\n",
      "19    NaN\n",
      "20    1.0\n",
      "Name: label, dtype: float64\n",
      "0     0\n",
      "1     1\n",
      "2     2\n",
      "3     1\n",
      "4     2\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     2\n",
      "9     2\n",
      "10    2\n",
      "11    0\n",
      "12    0\n",
      "13    2\n",
      "14    0\n",
      "15    0\n",
      "16    1\n",
      "17    2\n",
      "18    0\n",
      "19    2\n",
      "20    1\n",
      "Name: final_prediction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test[\"label\"])\n",
    "print(test[\"final_prediction\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
